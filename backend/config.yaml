# General Settings
data_dir: "./app/data"  # Path *inside* the Docker container

# Ollama Configuration
ollama:
  #base_url: "http://host.docker.internal:11434"  # Default for Docker Desktop, adjust if needed
   base_url: "http://localhost:11434"  # If Ollama runs on the host *outside* Docker on Linux

# Whisper Configuration
whisper:
  model: "base.en"  # Options: tiny.en, base.en, small.en, medium.en, large
  device: "cpu"  # or "cuda" if GPU is available and configured in Docker

# Tesseract Configuration
tesseract:
  cmd: "tesseract"  # Path to tesseract executable if not in PATH
  lang: "eng"  # Language pack(s) to use

# LangChain RAG Configuration
rag:
  chunk_size: 1000
  chunk_overlap: 150
  embedding_model_name: "nomic-embed-text"  # Example model name you have pulled in Ollama
  vector_store_path: "processed/vectorstore"  # Relative to data_dir

# Background Task Settings
background_tasks:
  max_concurrent_jobs: 2  # Limit simultaneous heavy processing tasks

# Summarization / Export Settings
summary:
  tts_engine: "coqui_tts"  # Placeholder - 'coqui_tts', 'bark', or 'none'
  tts_speaker_1: "tts_models/en/vctk/p225"  # Example Coqui speaker ID
  tts_speaker_2: "tts_models/en/vctk/p226"  # Example Coqui speaker ID
  summary_max_length: 500  # Tokens for text summary

# Database Configuration
database_url: "sqlite+aiosqlite:///{{ data_dir }}/db/app.db"  # SQLite inside container
